{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonada usage example notebook\n",
    "\n",
    "Notebooks are a great way to explore and experiment with data. Canonada allows you to use all catalog and pipelines features in a notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import canonada.catalog as catalog\n",
    "\n",
    "# Import project defined pipelines and systems\n",
    "os.chdir(\"..\")\n",
    "import pipelines\n",
    "import systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets showcase some of the catalog features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog sources:\n",
      "['raw_signals', 'stats', 'offset_signals_catalog', 'better_stats']\n"
     ]
    }
   ],
   "source": [
    "# List all available catalog sources\n",
    "print(\"Catalog sources:\")\n",
    "print(catalog.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{'section_1.offset': 5}\n"
     ]
    }
   ],
   "source": [
    "# List all available parameters\n",
    "print(\"Parameters:\")\n",
    "print(catalog.params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# List all available credentials\n",
    "print(\"Credentials:\")\n",
    "print(catalog.credentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a datahandler from the list of sources\n",
    "raw_signals_datahandler: catalog.Datahandler = catalog.get(\"raw_signals\")\n",
    "\n",
    "# Print a few rows of the data\n",
    "print(\"Raw signal data:\")\n",
    "for i, row in enumerate(raw_signals_datahandler):\n",
    "    print(row)\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the example pipeline system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 21:02:06,221 - canonada: [INFO]: Running pipeline system: 'example_system'\n",
      "2024-09-13 21:02:06,223 - canonada: [WARNING]: Path 'data/offset_signals' not found for json_multi datahandler. Creating it.\n",
      "2024-09-13 21:02:06,224 - canonada: [WARNING]: File data/stats.csv not found for csv_rows datahandler. Creating an empty file.\n",
      "2024-09-13 21:02:06,224 - canonada: [INFO]: Running pipeline: streaming_pipe\n",
      "2024-09-13 21:02:06,539 - canonada: [INFO]: Pipeline streaming_pipe finished\n",
      "2024-09-13 21:02:06,587 - canonada: [INFO]: Running pipeline: calculate_better_stats\n",
      "2024-09-13 21:02:06,713 - canonada: [INFO]: Pipeline calculate_better_stats finished\n"
     ]
    }
   ],
   "source": [
    "systems.example_system.example_system()\n",
    "\n",
    "# In the same way you can call any pipeline to run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a pipeline for a single datum (without the catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline output:\n",
      "Output keys:  dict_keys(['raw_signals', 'params:section_1.offset', 'offset_signals', 'offset_signals_catalog', 'max_values', 'mean_values', 'stats'])\n",
      "{'id': '80b57db2-55fb-4194-9c71-4bae5a237222', 'maximum': 5.999204361922914, 'mean': 5.516971098237362}\n"
     ]
    }
   ],
   "source": [
    "# Load a single data point from the datahandler\n",
    "signal_dict = raw_signals_datahandler[\"signal_0\"]\n",
    "\n",
    "# Run the pipeline with the data point\n",
    "pipeline_output = pipelines.example_pipelines.streaming_pipe.run_once({\"raw_signals\": signal_dict, \"params:section_1.offset\": 6})\n",
    "\n",
    "print(\"Pipeline output:\")\n",
    "print(\"Output keys: \", pipeline_output.keys())\n",
    "print(pipeline_output[\"stats\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
